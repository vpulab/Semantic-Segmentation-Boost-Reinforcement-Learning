{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGYGjiYPdjSf"
   },
   "source": [
    "## On semantic segmentation: training of a simplified model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pwCk2ajiAlJ"
   },
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FiTexagoMzo7",
    "outputId": "2c37fd40-6a29-4d4a-df2e-702285e9f117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data as data\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "#from torchvision.datasets.utils import download_file_from_google_drive\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from os.path import join\n",
    "import csv\n",
    "\n",
    "print('PyTorch version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4pCLAf0hkjp"
   },
   "source": [
    "#### Set up Hyperparameters + Enable GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__aK6FHnM0fa"
   },
   "outputs": [],
   "source": [
    "class configuration:\n",
    "  def __init__(self):\n",
    "    self.experiment_name = \"Training the Super Mario Segmentation Model\"\n",
    "    \n",
    "    # Paramters for the first part\n",
    "    self.pre_load    = \"True\" ## Load dataset in memory\n",
    "    self.pre_trained = \"True\"\n",
    "    self.num_classes = 6\n",
    "    self.ignore_label = 255\n",
    "    self.training_data_proportion = 0.8 # Proportion of images of the dataset to be used for training\n",
    "\n",
    "    self.lr    = 0.001  # 0.001 if pretrained weights from pytorch. 0.1 if scratch\n",
    "    self.epoch = 45     # Play with this if training takes too long\n",
    "    self.M = [37,42]         # If training from scratch, reduce learning rate at some point\n",
    "\n",
    "    self.batch_size = 4  # Training batch size\n",
    "    self.test_batch_size = 4  # Test batch size\n",
    "    self.model_file_name = \"MarioSegmentationModel.pth\"\n",
    "    \n",
    "    self.dataset_root = \"C:/Users/jmr/Desktop/Mario/dataset_generator/dataset\"\n",
    "    self.download   = False\n",
    "    \n",
    "    self.seed = 271828\n",
    "\n",
    "## Create arguments object\n",
    "args = configuration()\n",
    "\n",
    "# Make sure to nable GPU accele#ration!\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True  # fix the GPU to deterministic mode\n",
    "torch.manual_seed(args.seed)  # CPU seed\n",
    "torch.cuda.manual_seed_all(args.seed)  # GPU seed\n",
    "random.seed(args.seed)  # python seed for image transformation\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhchWqKCirhy"
   },
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsaqPO3ZM0uy"
   },
   "outputs": [],
   "source": [
    "class MarioDataset(data.Dataset):\n",
    "    def __init__(self, args, mode, transform_input=transforms.ToTensor(), transform_mask=transforms.ToTensor()):\n",
    "        self.args = args\n",
    "        self.folder = args.dataset_root\n",
    "\n",
    "        #If you change how you create the dataset you may need to modify this:\n",
    "        self.images_in_dataset = len(os.listdir(self.folder+\"/PNG\"))\n",
    "        training_images_no = int(self.images_in_dataset*0.8)\n",
    "        self.imgs = np.arange(training_images_no) if mode == 'train' else np.arange(training_images_no,self.images_in_dataset)\n",
    "\n",
    "        if len(self.imgs) == 0:\n",
    "            raise RuntimeError('Found 0 images, please check the data set or proportions')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.transform_input = transform_input\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "    # Default trasnformations on train data\n",
    "    def transform(self, image, mask):\n",
    "\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, (224,224))\n",
    "        \n",
    "        image = TF.crop(image,i,j,h,w)\n",
    "        mask  = TF.crop(mask,i,j,h,w)\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask  = TF.hflip(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    # Default trasnformations on test data\n",
    "    def test_transform(self, image, mask):\n",
    "        #224x224 center crop: \n",
    "        image = TF.center_crop(image,[224,224])\n",
    "        mask  = TF.center_crop(mask,[224,224])\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            img = Image.open(+self.folder+\"/PNG/\"+str(index)+\".png\").convert('RGB')\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            return str(index), img\n",
    "\n",
    "            #Load RGB image\n",
    "        img = Image.open(self.folder+\"/PNG/\"+str(index)+\".png\").convert('RGB')\n",
    "\n",
    "        if self.mode == 'train':\n",
    "\n",
    "            #Load class mask\n",
    "            mask = Image.open(self.folder+\"/Labels/\"+str(index)+\".png\")\n",
    "        else:\n",
    "            mask = Image.open(self.folder+\"/Labels/\"+str(index)+\".png\")\n",
    "\n",
    "            ##Transform using default transformations\n",
    "        if self.mode==\"train\":\n",
    "              img, mask = self.transform(img,mask)\n",
    "        else:\n",
    "              img, mask = self.test_transform(img,mask)\n",
    "\n",
    "        if self.transform_input is not None:\n",
    "           img = self.transform_input(img)\n",
    "        if self.transform_mask is not None:\n",
    "            mask = 255*self.transform_mask(mask)\n",
    "\n",
    "        return img, mask.long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oizECWIYj25V"
   },
   "source": [
    "### Training Epoch\n",
    "Per-pixel cross-entropy loss is to be computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDhMppSZM0yE"
   },
   "outputs": [],
   "source": [
    "def train_SemanticSeg(args, model, device, train_loader, optimizer, epoch):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    counter = 1\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "    \n",
    "    gts_all, predictions_all = [], []\n",
    "\n",
    "    for batch_idx, (images, mask) in enumerate(train_loader):\n",
    "\n",
    "        images, mask = images.to(device), mask.to(device)\n",
    "\n",
    "        outputs = model(images)['out']\n",
    " \n",
    "        #Aggregated per-pixel loss\n",
    "        loss = criterion(outputs, mask.squeeze(1))\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if counter % 15 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Learning rate: {:.6f}'.format(\n",
    "                epoch, int(counter * len(images)), len(train_loader.dataset),\n",
    "                100. * counter / len(train_loader), loss.item(),\n",
    "                optimizer.param_groups[0]['lr']))\n",
    "        counter = counter + 1\n",
    "    \n",
    "    return sum(train_loss) / len(train_loss) # per batch averaged loss for the current epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNgjOTrLkO6y"
   },
   "source": [
    "### Validation epoch\n",
    "Per-pixel cross-entropy loss is to be computed. \n",
    "To this iam, we rely on a function to extract the histogram of the predicted classes: _fast_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_t5JnRJM01j"
   },
   "outputs": [],
   "source": [
    "def _fast_hist(label_pred, label_true, num_classes):\n",
    "    mask = (label_true >= 0) & (label_true < num_classes)\n",
    "    hist = np.bincount(\n",
    "        num_classes * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n",
    "    return hist\n",
    "\n",
    "def testing(args, model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_per_batch = []\n",
    "    test_loss = 0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "    gts_all, predictions_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, mask) in enumerate(test_loader):\n",
    "\n",
    "            images, mask = images.to(device), mask.to(device)\n",
    "\n",
    "            outputs = model(images)['out']\n",
    "\n",
    "            loss = criterion(outputs,mask.squeeze(1))\n",
    "            loss_per_batch.append(loss.item())\n",
    "\n",
    "            # Adapt output size for histogram calculation.\n",
    "            preds = outputs.data.max(1)[1].squeeze(1).squeeze(0).cpu().numpy()\n",
    "            gts_all.append(mask.data.squeeze(0).cpu().numpy())\n",
    "            predictions_all.append(preds)\n",
    "\n",
    "    loss_per_epoch = [np.average(loss_per_batch)]\n",
    "\n",
    "    hist = np.zeros((args.num_classes, args.num_classes))\n",
    "    for lp, lt in zip(predictions_all, gts_all):\n",
    "        hist += _fast_hist(lp.flatten(), lt.flatten(), args.num_classes)\n",
    "\n",
    "    iou = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(np.arange(args.num_classes), iou)\n",
    "    plt.title('Class Accuracy in the validation set ')\n",
    "    plt.show()\n",
    "\n",
    "    mean_iou = np.nanmean(iou)\n",
    "\n",
    "    print('\\nTest set ({:.0f}): Average loss: {:.4f}, mIoU: {:.4f}\\n'.format(\n",
    "        len(test_loader.dataset), loss_per_epoch[-1], mean_iou))\n",
    "\n",
    "    return (loss_per_epoch, mean_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKMlp2NlmH82"
   },
   "source": [
    "### Dataloaders definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MF7Ff7L1M0-L",
    "outputId": "7b3cb105-bc56-454f-f4cf-e536f722d48d"
   },
   "outputs": [],
   "source": [
    "workers = 0 #Anything over 0 will crash on windows. On linux it works fine.\n",
    "\n",
    "trainset = MarioDataset(args, 'train')\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "\n",
    "testset = MarioDataset(args, 'val')\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muGeTEv-mTRE"
   },
   "source": [
    "### Define model and download pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lO3oPJZOmqnz",
    "outputId": "84628cf4-8af9-4aea-977a-8b57f9156a9e"
   },
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead,DeepLabV3\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "model = models.segmentation.deeplabv3_resnet50(\n",
    "        pretrained=True, progress=True)\n",
    "model.classifier = DeepLabHead(2048, 6)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WtS4Uo8mqnl"
   },
   "source": [
    "### Define the optimizer and the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNqYcOFOmPgu"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.M, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb1WHuxwlOTj"
   },
   "source": [
    "### Training loop for semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJPYLf1WM041",
    "outputId": "da5989cc-3f0b-4e24-cf7d-95c7b97ef9df"
   },
   "outputs": [],
   "source": [
    "loss_train_epoch = []\n",
    "loss_test_epoch = []\n",
    "acc_train_per_epoch = []\n",
    "acc_test_per_epoch = []\n",
    "new_labels = []\n",
    "\n",
    "cont = 0\n",
    "\n",
    "for epoch in range(1, args.epoch + 1):\n",
    "    st = time.time()\n",
    "    \n",
    "    print(\"DeepLabV3_Resnet50 training, epoch \" + str(epoch))\n",
    "    loss_per_epoch = train_SemanticSeg(args,model,device,train_loader,optimizer,scheduler)\n",
    "\n",
    "    loss_train_epoch += [loss_per_epoch]\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_per_epoch_test, acc_val_per_epoch_i = testing(args,model,device,test_loader)\n",
    "\n",
    "    loss_test_epoch += loss_per_epoch_test\n",
    "    acc_test_per_epoch += [acc_val_per_epoch_i]\n",
    "\n",
    "    if epoch == 1:\n",
    "        best_acc_val = acc_val_per_epoch_i\n",
    "        \n",
    "    else:\n",
    "        if acc_val_per_epoch_i > best_acc_val:\n",
    "            best_acc_val = acc_val_per_epoch_i\n",
    "\n",
    "    if epoch==args.epoch:\n",
    "        torch.save(model.state_dict(), \"./models/\"+args.model_file_name)\n",
    "\n",
    "    \n",
    "\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCkDMKvxm_qe"
   },
   "source": [
    "### Accuracy and loss curves for semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXsfSYAEfVFQ"
   },
   "outputs": [],
   "source": [
    "##Accuracy\n",
    "acc_test  = np.asarray(acc_test_per_epoch)\n",
    "\n",
    "#Loss per epoch\n",
    "loss_test  = np.asarray(loss_test_epoch)\n",
    "loss_train = np.asarray(loss_train_epoch)\n",
    "\n",
    "numEpochs = len(acc_test)\n",
    "epochs = range(numEpochs)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epochs, acc_test, label='Test Semantic, max acc: ' + str(np.max(acc_test)))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(epochs, loss_test, label='Test Semantic, min loss: ' + str(np.min(loss_test)))\n",
    "plt.plot(epochs, loss_train, label='Train Semantic, min loss: ' + str(np.min(loss_train)))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.segmentation.deeplabv3_resnet50(\n",
    "        pretrained=True, progress=True)\n",
    "# Added a Sigmoid activation after the last convolution layer\n",
    "model.classifier = DeepLabHead(2048, 6)\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/resnet_50.pth\"))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "id": "aesQ1wa9Eh2t",
    "outputId": "eca1371a-3f3e-4bee-f295-89be5c134601",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the helper function\n",
    "def decode_segmap(image, nc=21):\n",
    "  ## Color palette for visualization of the 21 classes\n",
    "  label_colors = np.array([(0, 0, 0),  # 0=background\n",
    "               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "               (0, 0,255), (127, 127, 0), (0, 255, 0), (255, 0, 0), (255, 255, 0),\n",
    "               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n",
    "               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
    "               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n",
    "\n",
    "  r = np.zeros_like(image).astype(np.uint8)\n",
    "  g = np.zeros_like(image).astype(np.uint8)\n",
    "  b = np.zeros_like(image).astype(np.uint8)\n",
    "  \n",
    "  for l in range(0, nc):\n",
    "    idx = image == l\n",
    "    r[idx] = label_colors[l, 0]\n",
    "    g[idx] = label_colors[l, 1]\n",
    "    b[idx] = label_colors[l, 2]\n",
    "    \n",
    "  rgb = np.stack([r, g, b], axis=2)\n",
    "  return rgb\n",
    "\n",
    "def segment(net, path, show_orig=True,transform=transforms.ToTensor(), dev='cuda'):\n",
    "  img = Image.open(path)\n",
    "  if show_orig: plt.imshow(img); plt.axis('off'); plt.show()\n",
    "  \n",
    "  input_image = transform(img).unsqueeze(0).to(dev)\n",
    "  out = net(input_image)['out'][0]\n",
    "  \n",
    "  segm = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n",
    "  segm_rgb = decode_segmap(segm)\n",
    "  plt.imshow(segm_rgb)\n",
    "  plt.axis('off')\n",
    "  #plt.savefig('1_1.png', format='png',dpi=300,bbox_inches = \"tight\")\n",
    "  plt.show()\n",
    "\n",
    "def compare(net,net2, path, show_orig=True,transform=transforms.ToTensor(), dev='cuda'):\n",
    "  img = Image.open(path)\n",
    "  if show_orig: plt.imshow(img); plt.axis('off'); plt.show()\n",
    "  \n",
    "  input_image = transform(img).unsqueeze(0).to(dev)\n",
    "  out = net(input_image)['out'][0]\n",
    "  \n",
    "  segm = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n",
    "  segm_rgb = decode_segmap(segm)\n",
    "  plt.imshow(segm_rgb)\n",
    "  plt.axis('off'); plt.show()\n",
    "\n",
    "  input_image = transform(img).unsqueeze(0).to(dev)\n",
    "  out = net2(input_image)['out'][0]\n",
    "  \n",
    "  segm = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n",
    "  segm_rgb = decode_segmap(segm)\n",
    "  plt.imshow(segm_rgb); plt.axis('off'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvz1VkNm5XCc",
    "outputId": "d159c7b2-93f6-4dbb-928d-3b5eba5c2c8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval() #Or batch normalization gives error\n",
    "\n",
    "\n",
    "frame =\"./Validation_real_dataset/PNG/4.png\"\n",
    "print(frame)\n",
    "segment(model,frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UHyGK6Nx2y2S"
   ],
   "name": "TFM training of a simplified PSPNet model and comparative evaluation of pretrained models",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('MarioRepoTest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4435cb80433d5e75921e07b62cc85d83a78f5df9403c63fb33e966afc1292da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
